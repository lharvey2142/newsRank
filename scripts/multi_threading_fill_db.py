knownrealSites = [    
    'http://www.cbsnews.com/',
    'https://www.msnbc.com/',
    'https://www.abcnews.go.com',
    'https://www.wsj.com',
    'http://www.foxnews.com',
    'https://www.nytimes.com',
    'https://apnews.com',
    'https://ap.org/en-us',
    'http://cnn.com', 
    'https://usnews.com'
    ]
knownFakeSites =[
    'http://www.theonion.com',
    'http://www.16WMPO.com',
    'http://www.24wpn.com',
    'http://www.ABCNews.com.co',
    'http://www.actualidadpanamericana.com',
    'http://www.AmericanPoliticNews.co',
    'http://www.AmericanPresident.co',
    'http://www.AMPosts.com',
    'http://www.ANews24.org/',
    'http://www.AngryPatriotMovement.com',
    'http://www.Anonjekloy.tk',
    'http://www.AssociatedMediaCoverage.com',
    'http://www.Aurora-News.us',
    'http://www.BB4SP.com',
    'http://www.BeforeItsNews.com',
    'http://www.BlackInsuranceNews.com',
    'http://www.BostonTribune.com',
    'http://www.BuzzFeedUSA.com',
    'http://www.CannaSOS.com',
    'http://www.Channel18News.com',
    'http://www.ChristianTimesNewspaper.com',
    'http://www.ChristianToday.info',
    'http://www.CivicTribune.com',
    'http://www.CivicTribune.com',
    'http://www.ClashDaily.com',
    'http://www.CNNews3.com',
    'http://www.Coed.com',
    'http://www.ConservativeDailyPost.com',
    'http://www.ConservativeFlashNews.com',
    'http://www.ConservativeSpirit.com',
    'http://www.DailyInfoBox.com',
    'http://www.DailyNews10.com',
    'http://www.DailyNews5.com',
    'http://www.DailyNewsPosts.info',
    'http://www.DailySnark.com',
    'http://www.DailySurge.com',
    'http://www.DailyUSAUpdate.com',
    'http://www.DamnLeaks.com',
    'http://www.DepartedMedia.com',
    'http://www.Disclose.tv',
    'http://www.DIYHours.net',
    'http://www.DonaldTrumpPOTUS45.com',
    'http://www.EmpireHerald.com',
    'http://www.EmpireNews.net',
    'http://www.EmpireSports.co',
    'http://www.En-Volve.com',
    'http://www.ENHLive.com',
    'http://www.FedsAlert.com',
    'http://www.FlashNewsCorner.com',
    'http://www.FreedomDaily.com',
    'http://www.FreeWoodPost.com',
    'http://www.FreshDailyReport.com',
    'http://www.GiveMeLiberty01.com',
    'http://www.GlobalPoliticsNow.com',
    'http://www.GummyPost.com',
    'http://www.HealthyCareAndBeauty.com',
    'http://www.HealthyWorldHouse.com',
    'http://www.InterestingDailyNews.com',
    'http://www.JewsNews.co.il',
    'http://www.KMT11.com',
    'http://www.Konkonsagh.biz',
    'http://www.KY12News.com',
    'http://www.LadyLibertysNews.com',
    'http://www.LastDeplorables.com',
    'http://www.LearnProgress.org',
    'http://www.LiberalPlug.com',
    'http://www.LibertyAlliance.com',
    'http://www.Local31News.com',
    'http://www.MadWorldNews.com',
    'http://www.MajorThoughts.com',
    'http://www.Mentor2day.com',
    'http://www.MetropolitanWorlds.com',
    'http://www.NationalReport.net',
    'http://www.NBC.com.co',
    'http://www.NeonNettle.com',
    'http://www.Nephef.com',
    'http://www.NewPoliticsToday.com',
    'http://www.News4KTLA.com',
    'http://www.NewsBreaksHere.com',
    'http://www.NewsBySquad.com',
    'http://www.NewsDaily12.com',
    'http://www.NewsExaminer.net',
    'http://www.NewsLeak.co',
    'http://www.Newslo.com',
    'http://www.NewzMagazine.com',
    'http://www.NotAllowedTo.com',
    'http://www.OccupyDemocrats.com',
    'http://www.OnePoliticalPlaza.com',
    'http://www.OpenMagazines.com',
    'http://www.Politicalo.com',
    'http://www.Politicono.com',
    'http://www.Politicops.com',
    'http://www.Politicot.com',
    'http://www.PoliticsUSANews.com',
    'http://www.President45DonaldTrump.com',
    'http://www.Prntly.com',
    'http://www.RedCountry.us',
    'http://www.RedRockTribune.com',
    'http://www.Religionlo.com',
    'http://www.ReligionMind.com',
    'http://www.Rogue-Nation3.com',
    'http://www.RumorJournal.com',
    'http://www.SatiraTribune.com',
    'http://www.Smag31.com',
    'http://www.SocialEverythings.com',
    'http://www.Success-Street.com',
    'http://www.SupremePatriot.com',
    'http://www.TDTAlliance.com',
    'http://www.TeaParty.org',
    'http://www.ThatViralFeed.net',
    'http://www.The-Insider.co',
    'http://www.TheBigRiddle.com',
    'http://www.TheInternetPost.net',
    'http://www.TheLastLineOfDefense.org',
    'http://www.TheMoralOfTheStory.us',
    'http://www.TheNationalMarijuanaNews.com',
    'http://www.TheNet24h.com',
    'http://www.TheNewYorkEvening.com',
    'http://www.ThePoliticalInsider.com',
    'http://www.TheRightists.com',
    'http://www.TheSeattleTribune.com',
    'http://www.TheTrumpMedia.com',
    'http://www.TheUSA-News.com',
    'http://www.TheWashingtonPress.com',
    'http://www.Times.com.mx',
    'http://www.TMZWorldNews.com',
    'http://www.TrueAmericans.me',
    'http://www.TrueTrumpers.com',
    'http://www.UndergroundNewsReport.com',
    'http://www.UniversePolitics.com',
    'http://www.UrbanImageMagazine.com',
    'http://www.USA-Radio.com',
    'http://www.USA-Television.com',
    'http://www.USADailyInfo.com',
    'http://www.USADailyPost.us',
    'http://www.USADailyTime.com',
    'http://www.USADoseNews.com',
    'http://www.USAFirstInformation.com',
    'http://www.USANewsToday.com',
    'http://www.USAPolitics24hrs.com',
    'http://www.USAPoliticsToday.com',
    'http://www.USAPoliticsZone.com',
    'http://www.USASnich.com',
    'http://www.USATodayNews.me',
    'http://www.USHealthyAdvisor.com',
    'http://www.USHealthyLife.com',
    'http://www.USHerald.com',
    'http://www.USInfoNews.com',
    'http://www.USPOLN.com',
    'http://www.USPostman.com',
    'http://www.ViralActions.com',
    'http://www.VoxTribune.com',
    'http://www.WashingtonFeed.com',
    'http://www.WashingtonPost.com.co',
    'http://www.WorldNewsDailyReport.com',
    'http://www.WorldPoliticsNow.com',
]

import sys
sys.path.append('/Users/froyvalencia/newsRank')
import os
os.environ.setdefault('DJANGO_SETTINGS_MODULE','mysite.settings')
import django
django.setup()

from django.contrib.auth.models import User
users = User.objects.all()

import newspaper
from newspaper import news_pool
import nltk
import tweetParser
from newsApp.models import Article

def loadNews(knownrealSites, s):    
    articles = Article.objects.all()
    #for a in articles:
    #print(a)
    papers = []
    for url in knownrealSites:
        real_paper = None
        try:
            real_paper = newspaper.build(url)
            papers.append(real_paper)
            print(url + ' contains ' + str(len(real_paper.articles)) + ' '+ s + ' articles')
        except: 
            print(url)
            print('url is bad')
            continue
    news_pool.set(papers, threads_per_source=8)
    news_pool.join()
    for paper in papers:
        for article in paper.articles:
            #due to multithreading above we can assume every article has had download called on it.
            #for article in real_paper.articles:
            try:
                #article.download()
                article.parse()
                #print('article.authors:**************************\n');print(article.authors)
                #print('article.text:**************************\n');print(article.text)
                #print('article.url:**************************\n');print(article.url)
                #print('article.title:**************************\n');print(article.title)
                #article.nlp()
                #print('keywords:**************************\n');print(article.keywords)
                #print('summary:**************************\n');print(article.summary)
            except:
                print('issue with download/parse')
                continue
            #x,y,z = tweetParser.getSentiment(url,2000)
            #print(article.publish_date)
            a = Article(
                address = article.url,
                title = article.title,
                body = article.text,
                date = article.publish_date,
                result = s,
                #positive = x,
                #negative = y,
                #neutral = z,
                )
                #article.parse()
                #article.nlp()
            try:
                a.save()
                print('**************************article SAVED**************************')
            except:
                print('**************** article failed to save with field **************')
                continue
if __name__ == "__main__":
    loadNews(knownrealSites,'reliable')
    loadNews(knownFakeSites,'unreliable')
